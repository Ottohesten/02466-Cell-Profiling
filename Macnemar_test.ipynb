{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from dataset_tools import OwnDataset, make_train_test_val_split\n",
    "from models import LatentClassifier_2, VAE_CELL_CNN, CELL_CNN_CLASSIFIER\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7774 78 25 20\n"
     ]
    }
   ],
   "source": [
    "tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = OwnDataset(transform=tf, path=r\"/Users/rasmusjensen/Documents/02466-Cell-Profiling/data_subset\")\n",
    "train_subset, test_subset, val_subset = make_train_test_val_split(dataset)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(dataset), len(train_loader), len(test_loader), len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"trained_models/\"\n",
    "\n",
    "latent_dim_256 = LatentClassifier_2(hidden_dim=512, latent_dim=256, num_classes=13)\n",
    "latent_dim_256.load_state_dict(torch.load(MODEL_DIR + f\"{latent_dim_256.__class__.__name__}_latent{latent_dim_256.latent_dim}_mean_best_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "latent_dim_2 = LatentClassifier_2(hidden_dim=4, latent_dim=2, num_classes=13)\n",
    "latent_dim_2.load_state_dict(torch.load(MODEL_DIR + f\"{latent_dim_2.__class__.__name__}_latent{latent_dim_2.latent_dim}_mean_best_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "Cell_CNN_Classifier = CELL_CNN_CLASSIFIER(input_dim=(3, 68, 68), hidden_dim=128, num_classes=13)\n",
    "Cell_CNN_Classifier.load_state_dict(torch.load(MODEL_DIR + f\"{Cell_CNN_Classifier.__class__.__name__}_best_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "Vae_Cell_CNN_256 = VAE_CELL_CNN(input_dim=(3, 68, 68), hidden_dim=512, latent_dim=256)\n",
    "Vae_Cell_CNN_256.load_state_dict(torch.load(MODEL_DIR + f\"{Vae_Cell_CNN_256.__class__.__name__}_latent{Vae_Cell_CNN_256.latent_dim}_mean_best_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "Vae_Cell_CNN_2 = VAE_CELL_CNN(input_dim=(3, 68, 68), hidden_dim=4, latent_dim=2)\n",
    "Vae_Cell_CNN_2.load_state_dict(torch.load(MODEL_DIR + f\"{Vae_Cell_CNN_2.__class__.__name__}_latent{Vae_Cell_CNN_2.latent_dim}_mean_best_model.pth\", map_location=torch.device('cpu')))\n",
    "\n",
    "models = [latent_dim_256, latent_dim_2, Cell_CNN_Classifier]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_accuracy_256_latent = []\n",
    "batch_accuracy_2_latent = []\n",
    "batch_accuracy_CNN = []\n",
    "\n",
    "for image, moa in train_loader:\n",
    "    latent_output = Vae_Cell_CNN_256(image)\n",
    "    x_hat, mu, sigma = latent_output[\"x_hat\"], latent_output[\"mu\"], latent_output[\"sigma\"]\n",
    "    pred_256 = latent_dim_256(mu)\n",
    "    batch_accuracy_256_latent.append((pred_256.argmax(1) == moa).cpu().numpy())\n",
    "\n",
    "    latent_output = Vae_Cell_CNN_2(image)\n",
    "    x_hat, mu, sigma = latent_output[\"x_hat\"], latent_output[\"mu\"], latent_output[\"sigma\"]\n",
    "    pred_2 = latent_dim_2(mu)\n",
    "    batch_accuracy_2_latent.append((pred_2.argmax(1) == moa).cpu().numpy())\n",
    "\n",
    "    batch_accuracy_CNN.append((Cell_CNN_Classifier(image).argmax(1) == moa).cpu().numpy())\n",
    "\n",
    "batch_accuracy_CNN = np.concatenate(batch_accuracy_CNN)\n",
    "batch_accuracy_256_latent = np.concatenate(batch_accuracy_256_latent)\n",
    "batch_accuracy_2_latent = np.concatenate(batch_accuracy_2_latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mcnemar(acc1, acc2):\n",
    "    n00 = n01 = n10 = n11 = 0\n",
    "    for i in range(len(acc1)):\n",
    "        if acc1[i] and acc2[i]:\n",
    "            n11 += 1\n",
    "        elif acc1[i] and not acc2[i]:\n",
    "            n10 += 1\n",
    "        elif not acc1[i] and acc2[i]:\n",
    "            n01 += 1\n",
    "        else:\n",
    "            n00 += 1\n",
    "    confusion_matrix = [[n00, n01], [n10, n11]]\n",
    "    print(f'Confusion Matrix: {confusion_matrix}')\n",
    "    result = mcnemar(confusion_matrix, exact=True)\n",
    "    print(f'statistic={result.statistic}, p-value={result.pvalue}')\n",
    "    if result.pvalue < 0.05:\n",
    "        print('Significant difference in performance (reject H0)')\n",
    "    else:\n",
    "        print('No significant difference in performance (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN vs Latent 256\n",
      "----------------\n",
      "Confusion Matrix: [[4968, 6], [1, 0]]\n",
      "statistic=1.0, p-value=0.125\n",
      "No significant difference in performance (fail to reject H0)\n",
      " \n",
      "Latent 256 vs Latent 2\n",
      "----------------\n",
      "Confusion Matrix: [[4969, 0], [6, 0]]\n",
      "statistic=0.0, p-value=0.03125\n",
      "Significant difference in performance (reject H0)\n",
      " \n",
      "Latent 2 vs CNN\n",
      "----------------\n",
      "Confusion Matrix: [[4974, 1], [0, 0]]\n",
      "statistic=0.0, p-value=1.0\n",
      "No significant difference in performance (fail to reject H0)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Perform McNemar's tests\n",
    "print(\"CNN vs Latent 256\")\n",
    "print(\"----------------\")\n",
    "compute_mcnemar(batch_accuracy_CNN, batch_accuracy_256_latent)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Latent 256 vs Latent 2\")\n",
    "print(\"----------------\")\n",
    "compute_mcnemar(batch_accuracy_256_latent, batch_accuracy_2_latent)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Latent 2 vs CNN\")\n",
    "print(\"----------------\")\n",
    "compute_mcnemar(batch_accuracy_2_latent, batch_accuracy_CNN)\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: [[4, 0], [1, 5]]\n",
      "statistic=0.0, p-value=1.0\n",
      "No significant difference in performance (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def compute_mcnemar(acc1, acc2):\n",
    "    n00 = n01 = n10 = n11 = 0\n",
    "    for i in range(len(acc1)):\n",
    "        if acc1[i] == 1 and acc2[i] == 1:\n",
    "            n11 += 1\n",
    "        elif acc1[i] == 1 and acc2[i] == 0:\n",
    "            n10 += 1\n",
    "        elif acc1[i] == 0 and acc2[i] == 1:\n",
    "            n01 += 1\n",
    "        else:\n",
    "            n00 += 1\n",
    "    confusion_matrix = [[n00, n01], [n10, n11]]\n",
    "    print(f'Confusion Matrix: {confusion_matrix}')\n",
    "    result = mcnemar(confusion_matrix, exact=True)\n",
    "    print(f'statistic={result.statistic}, p-value={result.pvalue}')\n",
    "    if result.pvalue < 0.05:\n",
    "        print('Significant difference in performance (reject H0)')\n",
    "    else:\n",
    "        print('No significant difference in performance (fail to reject H0)')\n",
    "\n",
    "\n",
    "#acc1 = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1]  \n",
    "#acc2 = [1, 0, 1, 0, 0, 1, 0, 0, 1, 1]  \n",
    "#compute_mcnemar(acc1, acc2)\n",
    "\n",
    "compute_mcnemar(batch_accuracy_CNN, batch_accuracy_256_latent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_accuracy_CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m compute_mcnemar(\u001b[43mbatch_accuracy_CNN\u001b[49m, batch_accuracy_256_latent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_accuracy_CNN' is not defined"
     ]
    }
   ],
   "source": [
    "compute_mcnemar(batch_accuracy_CNN, batch_accuracy_256_latent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
