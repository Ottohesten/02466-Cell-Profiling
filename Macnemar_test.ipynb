{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from models import LatentClassifier, VAE_CELL_CNN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mnist dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "\n",
    "from dataset_tools import OwnDataset, make_train_test_val_split\n",
    "#from plotting import show_img, loss_plots, accuracy_plots, plot_random_images, plot_image_comparison, plot_latent\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from models import LatentClassifier, VAE_CELL_CNN, CELL_CNN_CLASSIFIER, CELL_CNN_CLASSIFIER_2\n",
    "\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "print(cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488396 4884 1527 1221\n"
     ]
    }
   ],
   "source": [
    "val = True\n",
    "tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Lambda(lambda x: x.view(-1)) # notice that we dont flatten when we are going to use CNN\n",
    "])\n",
    "# dataset = OwnDataset(transform=tf, path = r\"C:\\Users\\vlbr1\\Downloads\\labelled_data-20240618T120814Z-001\\labelled_data\")\n",
    "dataset = OwnDataset(transform=tf, path=r\"C:\\Users\\Otto\\Desktop\\Fagprojekt_data\\labelled_data\")\n",
    "# dataset = OwnDataset(transform=tf)\n",
    "train_subset, test_subset, val_subset = make_train_test_val_split(dataset)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=True)\n",
    "\n",
    "print(len(dataset), len(train_loader), len(test_loader), len(val_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from models import LatentClassifier_2, VAE_CELL_CNN, CELL_CNN_CLASSIFIER, CELL_CNN_CLASSIFIER_2, VAE_CELL_CNN\n",
    "from loss_functions import loss_function\n",
    "# import mse loss\n",
    "\n",
    "\n",
    "# now we load the saved models into the model class\n",
    "MODEL_DIR = \"trained_models/\"\n",
    "\n",
    "\n",
    "latent_dim_256 = LatentClassifier_2(hidden_dim=512, latent_dim=256, num_classes=13)\n",
    "latent_dim_256.load_state_dict(torch.load(MODEL_DIR + f\"{latent_dim_256.__class__.__name__}_latent{latent_dim_256.latent_dim}_mean_best_model.pth\",map_location=torch.device('cpu')))\n",
    "\n",
    "latent_dim_2 = LatentClassifier_2(hidden_dim=4, latent_dim=2, num_classes=13)\n",
    "latent_dim_2.load_state_dict(torch.load(MODEL_DIR + f\"{latent_dim_2.__class__.__name__}_latent{latent_dim_2.latent_dim}_mean_best_model.pth\",map_location=torch.device('cpu')))\n",
    "\n",
    "Cell_CNN_Classifier = CELL_CNN_CLASSIFIER(input_dim=(3,68,68),hidden_dim=128, num_classes=13)\n",
    "Cell_CNN_Classifier.load_state_dict(torch.load(MODEL_DIR + f\"{Cell_CNN_Classifier.__class__.__name__}_best_model.pth\",map_location=torch.device('cpu')))\n",
    "\n",
    "Vae_Cell_CNN_256 = VAE_CELL_CNN(input_dim=(3,68,68), hidden_dim=512, latent_dim=256)\n",
    "Vae_Cell_CNN_256.load_state_dict(torch.load(MODEL_DIR + f\"{Vae_Cell_CNN_256.__class__.__name__}_latent{Vae_Cell_CNN_256.latent_dim}_mean_best_model.pth\",map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "Vae_Cell_CNN_2 = VAE_CELL_CNN(input_dim=(3,68,68), hidden_dim=4, latent_dim=2)\n",
    "Vae_Cell_CNN_2.load_state_dict(torch.load(MODEL_DIR + f\"{Vae_Cell_CNN_2.__class__.__name__}_latent{Vae_Cell_CNN_2.latent_dim}_mean_best_model.pth\",map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "# models = [vae_cnn_own]\n",
    "models = [latent_dim_256, latent_dim_2, Cell_CNN_Classifier]\n",
    "# models = [ae_cnn_own]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the classification performance across trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_accuracy_256_latent = []\n",
    "batch_accuracy_2_latent = []\n",
    "batch_accuracy_CNN = []\n",
    "for image, moa in train_loader:\n",
    "    # print(Cell_CNN_Classifier(image))\n",
    "    # print(moa)\n",
    "    # print(\"_________\")\n",
    "\n",
    "    \n",
    "    # for 256 dim latent space\n",
    "    latent_output = Vae_Cell_CNN_256(image)\n",
    "    x_hat, mu, sigma = latent_output[\"x_hat\"], latent_output[\"mu\"], latent_output[\"sigma\"]\n",
    "\n",
    "    pred_256 = latent_dim_256(mu)\n",
    "    batch_accuracy_256_latent.append(pred_256.argmax(1)== moa)\n",
    "\n",
    "\n",
    "    # for 2 dim latent space\n",
    "    latent_output = Vae_Cell_CNN_2(image)\n",
    "    x_hat, mu, sigma = latent_output[\"x_hat\"], latent_output[\"mu\"], latent_output[\"sigma\"]\n",
    "\n",
    "    pred_2 = latent_dim_2(mu)\n",
    "    batch_accuracy_2_latent.append(pred_2.argmax(1)== moa)\n",
    "\n",
    "\n",
    "    #Cell_CNN_Classifier(image) == moa\n",
    "    batch_accuracy_CNN.append((Cell_CNN_Classifier(image).argmax(1) == moa))\n",
    "\n",
    "\n",
    "\n",
    "    # print(batch_accuracy_CNN)\n",
    "    # print(batch_accuracy_256_latent)\n",
    "    # print(batch_accuracy_2_latent)\n",
    "    \n",
    "    \n",
    " # Converting to arrays\n",
    "batch_accuracy_CNN = np.concatenate(batch_accuracy_CNN)\n",
    "batch_accuracy_256_latent = np.concatenate(batch_accuracy_256_latent)\n",
    "batch_accuracy_2_latent = np.concatenate(batch_accuracy_2_latent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix + Macnemar Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent 256 vs CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38853, 7670], [40387, 225662]]\n",
      "statistic=7670.0, p-value=0.0\n",
      "Significant difference in performance (reject H0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "n00 = n01 = n10 = n11 = 0\n",
    "\n",
    "for i in range(len(batch_accuracy_CNN)):\n",
    "    if batch_accuracy_CNN[i] and batch_accuracy_256_latent[i]:\n",
    "        n11 += 1\n",
    "    elif batch_accuracy_CNN[i] and not batch_accuracy_256_latent[i]:\n",
    "        n10 += 1\n",
    "    elif not batch_accuracy_CNN[i] and batch_accuracy_256_latent[i]:\n",
    "        n01 += 1\n",
    "    else:\n",
    "        n00 += 1\n",
    "\n",
    "confusion_matrix = [[n00, n01], [n10, n11]]\n",
    "print(confusion_matrix)\n",
    "\n",
    "result = mcnemar(confusion_matrix, exact=True)\n",
    "print(f'statistic={result.statistic}, p-value={result.pvalue}')\n",
    "\n",
    "alpha = 0.05\n",
    "if result.pvalue < alpha:\n",
    "    print('Significant difference in performance (reject H0)')\n",
    "else:\n",
    "    print('No significant difference in performance (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent 256 vs Latent 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic=8511.0, p-value=0.0\n",
      "Significant difference in performance (reject H0)\n"
     ]
    }
   ],
   "source": [
    "n00 = n01 = n10 = n11 = 0\n",
    "# latent 256 vs latent 2 \n",
    "\n",
    "for i in range(len(batch_accuracy_256_latent)):\n",
    "    if batch_accuracy_256_latent[i] and batch_accuracy_2_latent[i]:\n",
    "        n11 += 1\n",
    "    elif batch_accuracy_256_latent[i] and not batch_accuracy_2_latent[i]:\n",
    "        n10 += 1\n",
    "    elif not batch_accuracy_256_latent[i] and batch_accuracy_2_latent[i]:\n",
    "        n01 += 1\n",
    "    else:\n",
    "        n00 += 1\n",
    "\n",
    "confusion_matrix = [[n00, n01], [n10, n11]]\n",
    "\n",
    "result = mcnemar(confusion_matrix, exact=True)\n",
    "print(f'statistic={result.statistic}, p-value={result.pvalue}')\n",
    "\n",
    "alpha = 0.05\n",
    "if result.pvalue < alpha:\n",
    "    print('Significant difference in performance (reject H0)')\n",
    "else:\n",
    "    print('No significant difference in performance (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent 2 vc CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic=6639.0, p-value=0.0\n",
      "Significant difference in performance (reject H0)\n"
     ]
    }
   ],
   "source": [
    "n00 = n01 = n10 = n11 = 0\n",
    "# latent 2 vs CNN\n",
    "\n",
    "for i in range(len(batch_accuracy_2_latent)):\n",
    "    if batch_accuracy_2_latent[i] and batch_accuracy_CNN[i]:\n",
    "        n11 += 1\n",
    "    elif batch_accuracy_2_latent[i] and not batch_accuracy_CNN[i]:\n",
    "        n10 += 1\n",
    "    elif not batch_accuracy_2_latent[i] and batch_accuracy_CNN[i]:\n",
    "        n01 += 1\n",
    "    else:\n",
    "        n00 += 1\n",
    "\n",
    "\n",
    "confusion_matrix = [[n00, n01], [n10, n11]]\n",
    "\n",
    "result = mcnemar(confusion_matrix, exact=True)\n",
    "print(f'statistic={result.statistic}, p-value={result.pvalue}')\n",
    "\n",
    "alpha = 0.05\n",
    "if result.pvalue < alpha:\n",
    "    print('Significant difference in performance (reject H0)')\n",
    "else:\n",
    "    print('No significant difference in performance (fail to reject H0)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[39884, 70098], [6639, 195951]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
